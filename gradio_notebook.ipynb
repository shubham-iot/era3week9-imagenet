{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "K4sl_p9c7tTB",
        "outputId": "fb4d1704-68bd-41e7-de1e-34163948869f"
      },
      "outputs": [],
      "source": [
        "!pip install gradio -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "87vksBbi-dEd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (2.0.1)\n",
            "Requirement already satisfied: torchvision in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (0.15.2)\n",
            "Requirement already satisfied: huggingface_hub in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (0.27.0)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
            "Requirement already satisfied: sympy in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from torch) (2.7.1)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from torchvision) (9.0.1)\n",
            "Requirement already satisfied: requests in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from torchvision) (2.32.3)\n",
            "Requirement already satisfied: numpy in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from huggingface_hub) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from huggingface_hub) (4.64.0)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from huggingface_hub) (2024.12.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from requests->torchvision) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gradio in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (4.44.1)\n",
            "Requirement already satisfied: huggingface_hub in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (0.27.0)\n",
            "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from gradio) (2.0.1)\n",
            "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from gradio) (0.27.2)\n",
            "Requirement already satisfied: fastapi<1.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from gradio) (0.115.6)\n",
            "Requirement already satisfied: ruff>=0.2.2 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from gradio) (0.8.4)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from gradio) (6.0)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from gradio) (9.0.1)\n",
            "Requirement already satisfied: ffmpy in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: jinja2<4.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from gradio) (2.11.3)\n",
            "Requirement already satisfied: gradio-client==1.3.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from gradio) (1.3.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from gradio) (3.5.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from gradio) (3.5.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: pydub in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: pydantic>=2.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from gradio) (2.10.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from gradio) (0.34.0)\n",
            "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: orjson~=3.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from gradio) (3.10.12)\n",
            "Requirement already satisfied: urllib3~=2.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from gradio) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from gradio) (6.4.5)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from gradio) (1.4.2)\n",
            "Requirement already satisfied: fsspec in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from gradio-client==1.3.0->gradio) (2024.12.0)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from gradio-client==1.3.0->gradio) (12.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from huggingface_hub) (4.64.0)\n",
            "Requirement already satisfied: requests in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: filelock in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from huggingface_hub) (3.6.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.2.0)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.3)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from fastapi<1.0->gradio) (0.41.3)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: certifi in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio) (2021.10.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from importlib-resources<7.0,>=1.3->gradio) (3.7.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.25.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.0.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.3.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2021.3)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from pydantic>=2.0->gradio) (2.27.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.4)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: click>=8.0.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.0.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\s37ja\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (2.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "wNKx3bGH7tVq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import json\n",
        "import gradio as gr\n",
        "from torchvision.models import resnet50\n",
        "from huggingface_hub import Repository, login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OILzsCEH0BDC"
      },
      "outputs": [],
      "source": [
        "from model import resnet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "at7VvfiG8OsL"
      },
      "outputs": [],
      "source": [
        "#model = resnet50()\n",
        "model_path = \"./Checkpoint/checkpoint-epcoh24_lr_point1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "YnbyiylB0Oqh"
      },
      "outputs": [],
      "source": [
        "def load_model(model_path):\n",
        "    model = resnet50()  # Create an instance of the ResNet-50 model\n",
        "    state_dict = torch.load(model_path, map_location='cpu')  # Load the state dictionary\n",
        "\n",
        "    # # Remove \"module.\" prefix if present\n",
        "    # if 'module.' in next(iter(state_dict.keys())):\n",
        "    #     state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n",
        "\n",
        "    model.load_state_dict(state_dict)  # Load the state dictionary\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34Vv-Oya0ol_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWIxxJ1F0Xog"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dAtpUebls9oz",
        "outputId": "01e56f14-e6f1-43d6-9f15-7b14c1788601"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-142844de7ef9>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_path, map_location=torch.device(\"cpu\"))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "_IncompatibleKeys(missing_keys=['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.conv3.weight', 'layer1.0.bn3.weight', 'layer1.0.bn3.bias', 'layer1.0.bn3.running_mean', 'layer1.0.bn3.running_var', 'layer1.0.downsample.0.weight', 'layer1.0.downsample.1.weight', 'layer1.0.downsample.1.bias', 'layer1.0.downsample.1.running_mean', 'layer1.0.downsample.1.running_var', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.conv3.weight', 'layer1.1.bn3.weight', 'layer1.1.bn3.bias', 'layer1.1.bn3.running_mean', 'layer1.1.bn3.running_var', 'layer1.2.conv1.weight', 'layer1.2.bn1.weight', 'layer1.2.bn1.bias', 'layer1.2.bn1.running_mean', 'layer1.2.bn1.running_var', 'layer1.2.conv2.weight', 'layer1.2.bn2.weight', 'layer1.2.bn2.bias', 'layer1.2.bn2.running_mean', 'layer1.2.bn2.running_var', 'layer1.2.conv3.weight', 'layer1.2.bn3.weight', 'layer1.2.bn3.bias', 'layer1.2.bn3.running_mean', 'layer1.2.bn3.running_var', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.conv3.weight', 'layer2.0.bn3.weight', 'layer2.0.bn3.bias', 'layer2.0.bn3.running_mean', 'layer2.0.bn3.running_var', 'layer2.0.downsample.0.weight', 'layer2.0.downsample.1.weight', 'layer2.0.downsample.1.bias', 'layer2.0.downsample.1.running_mean', 'layer2.0.downsample.1.running_var', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.conv3.weight', 'layer2.1.bn3.weight', 'layer2.1.bn3.bias', 'layer2.1.bn3.running_mean', 'layer2.1.bn3.running_var', 'layer2.2.conv1.weight', 'layer2.2.bn1.weight', 'layer2.2.bn1.bias', 'layer2.2.bn1.running_mean', 'layer2.2.bn1.running_var', 'layer2.2.conv2.weight', 'layer2.2.bn2.weight', 'layer2.2.bn2.bias', 'layer2.2.bn2.running_mean', 'layer2.2.bn2.running_var', 'layer2.2.conv3.weight', 'layer2.2.bn3.weight', 'layer2.2.bn3.bias', 'layer2.2.bn3.running_mean', 'layer2.2.bn3.running_var', 'layer2.3.conv1.weight', 'layer2.3.bn1.weight', 'layer2.3.bn1.bias', 'layer2.3.bn1.running_mean', 'layer2.3.bn1.running_var', 'layer2.3.conv2.weight', 'layer2.3.bn2.weight', 'layer2.3.bn2.bias', 'layer2.3.bn2.running_mean', 'layer2.3.bn2.running_var', 'layer2.3.conv3.weight', 'layer2.3.bn3.weight', 'layer2.3.bn3.bias', 'layer2.3.bn3.running_mean', 'layer2.3.bn3.running_var', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.conv3.weight', 'layer3.0.bn3.weight', 'layer3.0.bn3.bias', 'layer3.0.bn3.running_mean', 'layer3.0.bn3.running_var', 'layer3.0.downsample.0.weight', 'layer3.0.downsample.1.weight', 'layer3.0.downsample.1.bias', 'layer3.0.downsample.1.running_mean', 'layer3.0.downsample.1.running_var', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.conv3.weight', 'layer3.1.bn3.weight', 'layer3.1.bn3.bias', 'layer3.1.bn3.running_mean', 'layer3.1.bn3.running_var', 'layer3.2.conv1.weight', 'layer3.2.bn1.weight', 'layer3.2.bn1.bias', 'layer3.2.bn1.running_mean', 'layer3.2.bn1.running_var', 'layer3.2.conv2.weight', 'layer3.2.bn2.weight', 'layer3.2.bn2.bias', 'layer3.2.bn2.running_mean', 'layer3.2.bn2.running_var', 'layer3.2.conv3.weight', 'layer3.2.bn3.weight', 'layer3.2.bn3.bias', 'layer3.2.bn3.running_mean', 'layer3.2.bn3.running_var', 'layer3.3.conv1.weight', 'layer3.3.bn1.weight', 'layer3.3.bn1.bias', 'layer3.3.bn1.running_mean', 'layer3.3.bn1.running_var', 'layer3.3.conv2.weight', 'layer3.3.bn2.weight', 'layer3.3.bn2.bias', 'layer3.3.bn2.running_mean', 'layer3.3.bn2.running_var', 'layer3.3.conv3.weight', 'layer3.3.bn3.weight', 'layer3.3.bn3.bias', 'layer3.3.bn3.running_mean', 'layer3.3.bn3.running_var', 'layer3.4.conv1.weight', 'layer3.4.bn1.weight', 'layer3.4.bn1.bias', 'layer3.4.bn1.running_mean', 'layer3.4.bn1.running_var', 'layer3.4.conv2.weight', 'layer3.4.bn2.weight', 'layer3.4.bn2.bias', 'layer3.4.bn2.running_mean', 'layer3.4.bn2.running_var', 'layer3.4.conv3.weight', 'layer3.4.bn3.weight', 'layer3.4.bn3.bias', 'layer3.4.bn3.running_mean', 'layer3.4.bn3.running_var', 'layer3.5.conv1.weight', 'layer3.5.bn1.weight', 'layer3.5.bn1.bias', 'layer3.5.bn1.running_mean', 'layer3.5.bn1.running_var', 'layer3.5.conv2.weight', 'layer3.5.bn2.weight', 'layer3.5.bn2.bias', 'layer3.5.bn2.running_mean', 'layer3.5.bn2.running_var', 'layer3.5.conv3.weight', 'layer3.5.bn3.weight', 'layer3.5.bn3.bias', 'layer3.5.bn3.running_mean', 'layer3.5.bn3.running_var', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.conv3.weight', 'layer4.0.bn3.weight', 'layer4.0.bn3.bias', 'layer4.0.bn3.running_mean', 'layer4.0.bn3.running_var', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.0.downsample.1.running_mean', 'layer4.0.downsample.1.running_var', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.conv3.weight', 'layer4.1.bn3.weight', 'layer4.1.bn3.bias', 'layer4.1.bn3.running_mean', 'layer4.1.bn3.running_var', 'layer4.2.conv1.weight', 'layer4.2.bn1.weight', 'layer4.2.bn1.bias', 'layer4.2.bn1.running_mean', 'layer4.2.bn1.running_var', 'layer4.2.conv2.weight', 'layer4.2.bn2.weight', 'layer4.2.bn2.bias', 'layer4.2.bn2.running_mean', 'layer4.2.bn2.running_var', 'layer4.2.conv3.weight', 'layer4.2.bn3.weight', 'layer4.2.bn3.bias', 'layer4.2.bn3.running_mean', 'layer4.2.bn3.running_var', 'fc.weight', 'fc.bias'], unexpected_keys=[])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# from collections import OrderedDict\n",
        "\n",
        "# # Load the checkpoint\n",
        "# checkpoint = torch.load(checkpoint_path, map_location=torch.device(\"cpu\"))\n",
        "\n",
        "# # If the checkpoint has a \"state_dict\" key, use it\n",
        "# state_dict = checkpoint[\"state_dict\"] if \"state_dict\" in checkpoint else checkpoint\n",
        "\n",
        "# # Filter or rename keys to match the ResNet-50 architecture\n",
        "# new_state_dict = OrderedDict()\n",
        "# for key, value in state_dict.items():\n",
        "#     if key.startswith(\"module.\"):  # Remove 'module.' if checkpoint was trained with DataParallel\n",
        "#         new_key = key[7:]\n",
        "#     else:\n",
        "#         new_key = key\n",
        "#     if new_key in model.state_dict():  # Only add keys that exist in the ResNet-50 architecture\n",
        "#         # Check for shape mismatch and resize if necessary\n",
        "#         if value.shape != model.state_dict()[new_key].shape:\n",
        "#             print(f\"Resizing {new_key} from {value.shape} to {model.state_dict()[new_key].shape}\")\n",
        "#             value = value.reshape(model.state_dict()[new_key].shape)  # Resize the tensor\n",
        "\n",
        "#         new_state_dict[new_key] = value\n",
        "#     # else:\n",
        "#     #     print(f\"Skipping key: {new_key} not found in model\")  # Print skipped keys for debugging\n",
        "\n",
        "# # Load the filtered state_dict into the model\n",
        "# model.load_state_dict(new_state_dict, strict=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "-pTJL5orviam"
      },
      "outputs": [],
      "source": [
        "# # save the above nmodel with new name\n",
        "# model_save_dir = \"/content/model_colab\"\n",
        "# torch.save(model.state_dict(), model_save_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HY_NJ_5xs8Cn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ck6IAdXAGML",
        "outputId": "8a679ee0-9d2a-46cf-8db7-bc3d0004ecc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint keys: dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict', 'scheduler_state_dict', 'loss'])\n",
            "State dict keys: dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict', 'scheduler_state_dict', 'loss'])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-5-6bf15358f4bd>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_path, map_location=torch.device(\"cpu\"))\n"
          ]
        }
      ],
      "source": [
        "# checkpoint = torch.load(checkpoint_path, map_location=torch.device(\"cpu\"))\n",
        "# print(\"Checkpoint keys:\", checkpoint.keys())\n",
        "\n",
        "# if \"state_dict\" in checkpoint:\n",
        "#     print(\"State dict keys:\", checkpoint[\"state_dict\"].keys())\n",
        "# else:\n",
        "#     print(\"State dict keys:\", checkpoint.keys())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ohRd9YHwGwJ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xFFxUJNAGXo"
      },
      "outputs": [],
      "source": [
        "# tokenizer_path = \"/content/imagenet_class_index.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "OPghGoYgBiYq"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(image):\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    image = image.convert(\"RGB\")  # Ensure image is in RGB format\n",
        "    image = preprocess(image)  # Apply transformations\n",
        "    image = image.unsqueeze(0)  # Add batch dimension\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "CKIPCcseBrWd"
      },
      "outputs": [],
      "source": [
        "# Prediction function\n",
        "def predict(image):\n",
        "    image_tensor = preprocess_image(image)\n",
        "    with torch.no_grad():\n",
        "        output = model(image_tensor)\n",
        "        probabilities = torch.nn.functional.softmax(output, dim=1)\n",
        "        top5_probabilities, top5_indices = probabilities.topk(5)\n",
        "\n",
        "    results = {}\n",
        "    for i in range(5):\n",
        "        class_index = top5_indices[0][i].item()\n",
        "        class_label = class_labels.get(str(class_index), \"Unknown class\")\n",
        "        results[class_label] = top5_probabilities[0][i].item()  # Store label and probability in a dictionary\n",
        "    print(\"See the prediction result : \", results)\n",
        "    return results  # Return the results as a dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "bW4MdC3FwFiJ"
      },
      "outputs": [],
      "source": [
        "#tokenizer_path = \"/content/imagenet_class_index.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "xWM8xmxo1DeN"
      },
      "outputs": [],
      "source": [
        "# Load class index mapping\n",
        "def load_class_labels(label_path):\n",
        "    with open(label_path, 'r') as f:\n",
        "        class_labels = json.load(f)\n",
        "    return class_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "34j12BSb14wV"
      },
      "outputs": [],
      "source": [
        "def load_model(model_path):\n",
        "    model = resnet50()  # Create an instance of the ResNet-50 model\n",
        "    checkpoint = torch.load(model_path, map_location='cpu')  # Load the checkpoint\n",
        "\n",
        "    # Access the 'model_state_dict' key within the checkpoint\n",
        "    state_dict = checkpoint['model_state_dict']\n",
        "\n",
        "    # Remove \"module.\" prefix if present (common when using DataParallel)\n",
        "    if 'module.' in next(iter(state_dict.keys())):\n",
        "        state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n",
        "\n",
        "    model.load_state_dict(state_dict)  # Load the state dictionary\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-uPYIPZwNLU",
        "outputId": "a33d192c-4939-44c1-fda5-6b6641d7f1aa"
      },
      "outputs": [],
      "source": [
        "# Load model and class labels\n",
        "# model_path = 'model.pt'  # Path to the trained model\n",
        "model_path = \"./Checkpoint/checkpoint-epcoh24_lr_point1\"\n",
        "label_path = 'imagenet_class_index.json'  # Path to the class index mapping\n",
        "model = load_model(model_path)\n",
        "class_labels = load_class_labels(label_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ygoyiQBx2FTI"
      },
      "outputs": [],
      "source": [
        "# Create Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=gr.Image(type=\"pil\"),\n",
        "    outputs=gr.Label(num_top_classes=5),\n",
        "    title=\"Image Classification using ResNet 50 Model trained on Imagenet 1000 dataset\",\n",
        "    description=\"Upload an image to get the top-5 predictions.\"\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "cIVrfvSP2FGB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "See the prediction result :  {'lion, king of beasts, Panthera leo': 0.9751031994819641, 'Tibetan mastiff': 0.017351044341921806, 'chow, chow chow': 0.003145449096336961, 'Persian cat': 0.0004533762112259865, 'Pekinese, Pekingese, Peke': 0.0002895498473662883}\n",
            "See the prediction result :  {'German shepherd, German shepherd dog, German police dog, alsatian': 0.9453887343406677, 'malinois': 0.02955769933760166, 'kelpie': 0.007483848370611668, 'dingo, warrigal, warragal, Canis dingo': 0.0026456655468791723, 'Australian terrier': 0.0022577173076570034}\n",
            "See the prediction result :  {'German shepherd, German shepherd dog, German police dog, alsatian': 0.9453887343406677, 'malinois': 0.02955769933760166, 'kelpie': 0.007483848370611668, 'dingo, warrigal, warragal, Canis dingo': 0.0026456655468791723, 'Australian terrier': 0.0022577173076570034}\n",
            "See the prediction result :  {'tree frog, tree-frog': 0.8318064212799072, 'tailed frog, bell toad, ribbed toad, tailed toad, Ascaphus trui': 0.14911164343357086, 'bullfrog, Rana catesbeiana': 0.009369793348014355, 'African chameleon, Chamaeleo chamaeleon': 0.0029506904538720846, 'green lizard, Lacerta viridis': 0.002211141400039196}\n",
            "See the prediction result :  {'lion, king of beasts, Panthera leo': 0.9751031994819641, 'Tibetan mastiff': 0.017351044341921806, 'chow, chow chow': 0.003145449096336961, 'Persian cat': 0.0004533762112259865, 'Pekinese, Pekingese, Peke': 0.0002895498473662883}\n",
            "See the prediction result :  {'West Highland white terrier': 0.22784939408302307, 'Chihuahua': 0.1920958161354065, 'Norwich terrier': 0.15740036964416504, 'toy terrier': 0.030548248440027237, 'Pembroke, Pembroke Welsh corgi': 0.02022257260978222}\n",
            "See the prediction result :  {'Chihuahua': 0.7555046081542969, 'toy terrier': 0.148393452167511, 'Pembroke, Pembroke Welsh corgi': 0.024826698005199432, 'Mexican hairless': 0.01391909271478653, 'Cardigan, Cardigan Welsh corgi': 0.010404368862509727}\n",
            "See the prediction result :  {'suit, suit of clothes': 0.2690926492214203, 'Windsor tie': 0.2586955428123474, 'bow tie, bow-tie, bowtie': 0.15798425674438477, \"academic gown, academic robe, judge's robe\": 0.06467702984809875, 'lab coat, laboratory coat': 0.03081275150179863}\n"
          ]
        }
      ],
      "source": [
        "# Launch the app\n",
        "iface.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSlUvqbD2E2Z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBN3IhMB2Emp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
